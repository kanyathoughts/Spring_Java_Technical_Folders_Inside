server:
    port: 8080
    compression:
        enabled: true
        mime-types: application/json,application/xml,application/javascript,text/html,text/xml,text/plain,text/css,text/csv,text/javascript
        min-response-size: 2048
    servlet:
        context-path: /
keycloak:
    registration-id: mining-keycloak
    auth-server-url: http://localhost:8180/auth
    realm: mining
    client-id: backend
    client-name: mining-api-server
    user-name-attribute: preferred_username
spring:
    main:
        allow-circular-references: true
    security:
         oauth2:
            client:
               registration:
                   mining-keycloak:
                      client-id: ${keycloak.client-id}
                      client-name: ${keycloak.name}
                      provider: keycloak
                      scope: openid, profile
                      redirect-uri: "{baseUrl}/login/oauth2/code/{registrationId}"
                      authorization-grant-type: authorization_code
               provider:
                   keycloak:
                      token-uri: ${keycloak.auth-server-url}/realms/${keycloak.realm}/protocol/openid-connect/token
                      authorization-uri: ${keycloak.auth-server-url}/realms/${keycloak.realm}/protocol/openid-connect/auth
                      user-info-uri: ${keycloak.auth-server-url}/realms/${keycloak.realm}/protocol/openid-connect/userinfo
                      jwk-set-uri: ${keycloak.auth-server-url}/realms/${keycloak.realm}/protocol/openid-connect/certs
                      user-name-attribute: ${keycloak.user-name-attribute}
            resourceserver:
                 jwt:
                   issuer-uri: ${keycloak.auth-server-url}/realms/${keycloak.realm}
    datasource:
        enabled: false
        hikari:
            minimum-idle: 5
            maximum-pool-size: 50
            pool-name: OrientDBPool
            auto-commit: false
        driver-class-name: &driverClassName com.orientechnologies.orient.jdbc.ConcurrentOrientJdbcDriver
        url: jdbc:orient:remote:localhost:2424/mining
        username: root
        password: Worx2000
        type: com.zaxxer.hikari.HikariDataSource
    flyway:
        enabled: false
        encoding: CP1252
        locations: classpath:db/migration
        # The following changes are for flyway configuration to directly connect to db instead of using spring datasource. Do not change the
        # following configurations
        driver-class-name: *driverClassName
        user: ${spring.datasource.username}
        password: ${spring.datasource.password}
        url: ${spring.datasource.url}
    http:
        multipart:
            max-file-size: 2GB
            max-request-size: 2GB
    servlet:
        multipart:
            max-file-size: 2GB
            max-request-size: 2GB
    sleuth:
        async:
            ignored-beans: job-executor-service, task-executor-service, local-task-executor-service, heartbeat-executor-service
    graphql:
        path: /api/v2/graphql
        schema.printer.enabled: true
        graphiql.enabled: true

management:
        endpoint:
            health:
                show-details: always
        endpoints:
            web:
                exposure:
                    include: health, info, prometheus, metrics, threaddump, loggers, logfile, httptrace, scheduledtasks, db

postgres:
    enabled: true
#    max-schema-version: 1
    datasource: &pgDatasource
        driver-class-name: org.postgresql.Driver
        jdbc-url: jdbc:postgresql://localhost:5432/mining
        username: mining
        password: Worx2000
        type: com.zaxxer.hikari.HikariDataSource
        pool-name: PostgresPool
        minimum-idle: 5
        maximum-pool-size: 50
        connection-test-query: SELECT 1
        auto-commit: true
# dbcutter database is required to pull Module-SQL information in Reachability block table view
dbcutter-db-postgres:
    enabled: false
    datasource:
        <<: *pgDatasource
#       jdbc-url: jdbc:postgresql://0.0.0.0:5432/dbcutter
#       username: root
#       password: Worx2000
        pool-name: PostgresPoolDbCutter
routes:
    api:
        /api/
ff4j:
    webapi:
        authentication: false
        authorization: false
job-api:
     cluster: &clusterConfig
        name: standalone
        nodeNameStrategy: hostname
        mode: standalone
        network:
            port: 5710
            portAutoIncrement: true
external-parsing:
    enabled: false
    cluster: *clusterConfig
# activity during server startup
startup:
    # Submits a background deletion job when there are any client(s) or project(s) marked for deletion. This job would consumes lots of resources.
    background-deletion-job: true
configuration:
    # enable execution of legacy contributors
    discovery-enable-legacy-contributors: true
    # enable execution of Dawn (Discovery 2.0) contributors
    discovery-enable-dawn-contributors: true
    # maximum number of fetched modules in the cache 
    dawn-fetch-module-cache-size: 20000
    # maximum number of found module (moduleIds) in the cache 
    dawn-find-module-cache-size: 100000
    # maximum number of entries in the Discovery parse result cache (0 disables cache)
    discovery-parse-result-cache-size: 10000
    # maximum number of entries in the Discovery lightweight parse result cache (0 disables cache)
    discovery-lightweight-parse-result-cache-size: 1000
    # maximum number of entries in the Discovery module repository cache (0 disables cache)
    discovery-module-repository-cache-size: 200000
    # maximum number of entries in the Discovery source object cache (0 disables cache)
    discovery-source-object-cache-size: 100000
    # maximum number of bytes in the Discovery source code cache (0 disables cache)
    discovery-source-code-cache-size: 2147483648
    # true uses strong keys and values in caches, false weak keys and soft values
    discovery-cache-strong-references: false
    # true uses the restart file discoverMetricsRestartFile in jobResults folder to restart from the state stored by the latest discovery run
    # Attention: this may ignore any additionally added or updated source objects
    discovery-restart-enabled: false
    # maximum number of uncompressed bytes that may be read in a Discovery source upload to prevent Zip Bomb attacks.
    # If the value is 0 or negative, the checks are disabled.
    discovery-source-upload-maximum-size: 10000000000
    # maximum compression ratio allowed for a zip file.
    # If the value is 0 or negative, the checks are disabled.
    discovery-source-upload-maximum-ratio: 100
    # maximum number entries allowed inside a zip file.
    # If the value is 0 or negative, the checks are disabled.
    discovery-source-upload-maximum-entries: 1000000

    # maximum number of task threads to be used for the computation of call chains
    # A value less than 0 means that all available processors are used which can significantly slow down other running jobs and cause that the
    # UI is unresponsive while call chains are computed
    call-chain-maximum-export-threads: 8
    # maximum number of CSV lines that can be exported by each single call chain job
    # A value less than 1 means that no limit is used for the CSV export
    call-chain-maximum-csv-export-lines: 5000000
    # used in DNA analysis
    # reduce this size when OutOfMemory error encountered in DNA similarity computation phase (0 disables partitioning)
    discovery-dna-similarity-partition-size: 1000
    # Setting this to true, reduces the amount of data persisted into database however DNA rerun would take same amount of time as the first run.
    # when this set to false, it takes longer time in the first run however the rerun would be much faster.
    discovery-dna-optimal-persist: false
    # maximum number of entries in the Mining aggregation cache (0 disables cache)
    mining-aggregation-cache-size: 10000
    # maximum number of entries in the Mining hotspot cache (0 disables cache)
    mining-hotspot-cache-size: 10000
    # maximum number of entries in the Mining module statistics cache (0 disables cache)
    mining-module-statistics-cache-size: 10000
    # maximum number of entries in the Mining taxonomy aggregation (0 disables cache)
    mining-taxonomy-aggregation-cache-size: 10000
    # maximum number of entries in the Mining taxonomy category aggregation (0 disables cache)
    mining-taxonomy-category-aggregation-cache-size: 10000
    # maximum number of entries in the Discovery model DNA cache (0 disables cache)
    discovery-model-dna-cache-size: 10000
    # link to an external utilities.xml repository (Default is CF Repository)
    external-utility-repo-url: "http://appmodcf.deloitte.com/utilities-repo-ui/utilities"
    # if this is true it is required to add an extension that adds a bean of type GenAIModulePermissionChecker for the server to start
    gen-ai-require-filtering: false

springdoc:
  pathsToMatch: /**
  packagesToScan: innowake.mining.server.controller
  springdoc.swagger-ui.path: /swagger-ui.html
  springdoc.api-docs.resolve-schema-properties: true
  
mining:
    taxonomies:
        technicalTaxonomyCategoryName: Technical Taxonomies
        defaultTaxonomyCategoryName: Business Taxonomies
    cookieId:
    genAI:
        url:
        apiKey:
        plugIn:
        responseFormat: JSON # or TEXT, ensure availablity with the above plugin
        maxNewTokens:
        temperature:
        doSample:
        tokenRateLimit:
        maxParallelTasks:
        pathSegment:
            # This is expecting the path segment including the "/"
            moduleDescription:
            annotationDescription:
        semanticSearchUrl: # Points to GenAI backend where Semantic Search Plugin is deployed
        promptServiceUrl:
        retrieverTopK:
        # maximum number of prompts in the prompt cache
        prompt-cache-size: 100
        # the time in seconds after which the prompt cache is invalidated
        prompt-cache-duration: 30
        annotationKnowledgeCategory: VARIABLE_DESCRIPTION # the category/index to query in the knowledge service for Annotations
    metadata:
        maxZipImportSizeInMB:
cors:
    allowed-origins:
        # This is expecting CORS origin URLs

# Uncomment to configure fixed URL for mining-opensearch
#mining-opensearch:
#    url: http://localhost:8081
